{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07a8a6db",
   "metadata": {},
   "source": [
    "Referenced  - MCP build apps with Anthropic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebec5f6",
   "metadata": {},
   "source": [
    "#### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cbc4fe59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arxiv\n",
    "import json\n",
    "import os\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "import anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a2df3c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAPER_DIR = \"papers\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613e1739",
   "metadata": {},
   "source": [
    "Below function will extract information based on the topic provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f1bd2259",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_papers(topic: str, max_results: int = 5) -> List[str]:\n",
    "    \"\"\"\n",
    "    Search for papers on arXiv based on a topic and store their information.\n",
    "    \n",
    "    Args:\n",
    "        topic: The topic to search for\n",
    "        max_results: Maximum number of results to retrieve (default: 5)\n",
    "        \n",
    "    Returns:\n",
    "        List of paper IDs found in the search\n",
    "    \"\"\"\n",
    "    \n",
    "    #use arxiv to find papers\n",
    "    client = arxiv.Client()\n",
    "    \n",
    "    # search for most relavant articles matchinng queryed topic\n",
    "    search = arxiv.Search(\n",
    "        query=topic,\n",
    "        max_results=max_results,\n",
    "        sort_by = arxiv.SortCriterion.Relevance\n",
    "    )\n",
    "    \n",
    "    papers = client.results(search)\n",
    "    \n",
    "    #create directory to store papers\n",
    "    path = os.path.join(PAPER_DIR, topic.lower().replace(\" \", \"_\"))\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    \n",
    "    file_path = os.path.join(path, \"papers_info.json\")\n",
    "    \n",
    "    #try to load existing papers\n",
    "    try:\n",
    "        with open(file_path, \"r\") as f:\n",
    "            papers_info = json.load(f)\n",
    "    except (FileNotFoundError, json.JSONDecodeError):\n",
    "        papers_info = {}\n",
    "        \n",
    "    #process each paper and add to papers_info\n",
    "    \n",
    "    paper_ids = []\n",
    "    for paper in papers:\n",
    "        paper_ids.append(paper.get_short_id())\n",
    "        paper_info = {\n",
    "            \"title\": paper.title,\n",
    "            \"summary\": paper.summary,\n",
    "            \"authors\": [author.name for author in paper.authors],\n",
    "            \"published\": paper.published.isoformat(),\n",
    "            \"updated\": paper.updated.isoformat(),\n",
    "            \"pdf_url\": paper.pdf_url,\n",
    "            \"doi\": paper.doi\n",
    "        }\n",
    "        papers_info[paper.get_short_id()] = paper_info\n",
    "        \n",
    "    #save papers info to json file\n",
    "    with open(file_path, \"w\") as f:\n",
    "        json.dump(papers_info, f, indent = 2)\n",
    "    \n",
    "    print(f\"Results are saved in {file_path}\")\n",
    "    \n",
    "    return paper_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "749d336a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are saved in papers/machine_learning/papers_info.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['1909.03550v1',\n",
       " '1811.04422v1',\n",
       " '1707.04849v1',\n",
       " '1909.09246v1',\n",
       " '2301.09753v1']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_papers(\"machine learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6aa99e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_info(paper_id: str) -> str:\n",
    "    \"\"\"\n",
    "    Search for information about a specific paper across all topic directories.\n",
    "    \n",
    "    Args:\n",
    "        paper_id: The ID of the paper to look for\n",
    "        \n",
    "    Returns:\n",
    "        JSON string with paper information if found, error message if not found\n",
    "    \"\"\"\n",
    "    \n",
    "    for item in os.listdir(PAPER_DIR):\n",
    "        item_path = os.path.join(PAPER_DIR, item)\n",
    "        if os.path.isdir(item_path):\n",
    "            file_path = os.path.join(item_path, \"papers_info.json\")\n",
    "            if os.path.isfile(file_path):\n",
    "                try:\n",
    "                    with open(file_path, \"r\") as json_file:\n",
    "                        papers_info = json.load(json_file)\n",
    "                        if paper_id in papers_info:\n",
    "                            return json.dumps(papers_info[paper_id], indent=2)\n",
    "                except (FileNotFoundError, json.JSONDecodeError) as e:\n",
    "                    print(f\"Error reading {file_path}: {str(e)}\")\n",
    "                    continue\n",
    "            \n",
    "    return f\"There's is no saved information related to paper ID {paper_id}.\"\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f4df486c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"title\": \"Towards Modular Machine Learning Solution Development: Benefits and Trade-offs\",\\n  \"summary\": \"Machine learning technologies have demonstrated immense capabilities in\\\\nvarious domains. They play a key role in the success of modern businesses.\\\\nHowever, adoption of machine learning technologies has a lot of untouched\\\\npotential. Cost of developing custom machine learning solutions that solve\\\\nunique business problems is a major inhibitor to far-reaching adoption of\\\\nmachine learning technologies. We recognize that the monolithic nature\\\\nprevalent in today\\'s machine learning applications stands in the way of\\\\nefficient and cost effective customized machine learning solution development.\\\\nIn this work we explore the benefits of modular machine learning solutions and\\\\ndiscuss how modular machine learning solutions can overcome some of the major\\\\nsolution engineering limitations of monolithic machine learning solutions. We\\\\nanalyze the trade-offs between modular and monolithic machine learning\\\\nsolutions through three deep learning problems; one text based and the two\\\\nimage based. Our experimental results show that modular machine learning\\\\nsolutions have a promising potential to reap the solution engineering\\\\nadvantages of modularity while gaining performance and data advantages in a way\\\\nthe monolithic machine learning solutions do not permit.\",\\n  \"authors\": [\\n    \"Samiyuru Menik\",\\n    \"Lakshmish Ramaswamy\"\\n  ],\\n  \"published\": \"2023-01-23T22:54:34+00:00\",\\n  \"updated\": \"2023-01-23T22:54:34+00:00\",\\n  \"pdf_url\": \"http://arxiv.org/pdf/2301.09753v1\",\\n  \"doi\": null\\n}'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_info('2301.09753v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e8fbe8",
   "metadata": {},
   "source": [
    "#### Tool Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "79036074",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"name\": \"search_papers\",\n",
    "        \"description\": \"Search for papers on arXiv based on a topic and store their information.\",\n",
    "        \"input_schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"topic\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The topic to search for\"\n",
    "                }, \n",
    "                \"max_results\": {\n",
    "                    \"type\": \"integer\",\n",
    "                    \"description\": \"Maximum number of results to retrieve\",\n",
    "                    \"default\": 5\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"topic\"]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"extract_info\",\n",
    "        \"description\": \"Search for information about a specific paper across all topic directories.\",\n",
    "        \"input_schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"paper_id\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The ID of the paper to look for\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"paper_id\"]\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfd4378",
   "metadata": {},
   "source": [
    "#### Tool Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "85798f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_tool_function = {\n",
    "    \"search_papers\": search_papers,\n",
    "    \"extract_info\": extract_info\n",
    "}\n",
    "\n",
    "def execute_tool(tool_name, tool_args):\n",
    "    \n",
    "    result = mapping_tool_function[tool_name](**tool_args)\n",
    "    \n",
    "    if result is None:\n",
    "        result = \"operation completed but no result found\"\n",
    "        \n",
    "    elif isinstance(result, list):\n",
    "        result = \", \".join(result)\n",
    "        \n",
    "    elif isinstance(result, dict):\n",
    "        #first convert to formatted json\n",
    "        result = json.dumps(result, indent=2)\n",
    "        \n",
    "    else:\n",
    "        result = str(result)\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8c352b",
   "metadata": {},
   "source": [
    "#### Chatbot code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "56d1d1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "client = anthropic.Anthropic()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d83cd3",
   "metadata": {},
   "source": [
    "#### Query processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d4fe9e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_query(query):\n",
    "    \n",
    "    messages = [{'role': 'user', 'content': query}]\n",
    "    \n",
    "    response = client.messages.create(max_tokens = 2020, \n",
    "                                      model = 'claude-3-7-sonnet-20250219',\n",
    "                                      messages = messages,\n",
    "                                      tools = tools)\n",
    "    \n",
    "    process_query = True\n",
    "    \n",
    "    while process_query:\n",
    "        assistant_content = []\n",
    "        \n",
    "        for content in response.content:\n",
    "            if content.type == \"text\":\n",
    "                \n",
    "                print(content.text)\n",
    "                assistant_content.append(content)\n",
    "                \n",
    "                if len(response.content) == 1:\n",
    "                    proccess_query = False\n",
    "                    \n",
    "            elif content.type == \"tool_use\":\n",
    "                \n",
    "                assistant_content.append(content)\n",
    "                messages.append({'role': 'assistant', 'content': assistant_content})\n",
    "                \n",
    "                tool_id = content.id\n",
    "                tool_args = content.input\n",
    "                tool_name = content.name\n",
    "                \n",
    "                print(f\"calling tool {tool_name} with args {tool_args}\")\n",
    "                result = execute_tool(tool_name, tool_args)\n",
    "                \n",
    "                messages.append({'role': 'tool', 'content': [\n",
    "                    {\n",
    "                        'type' : \"tool_result\",\n",
    "                        \"tool_use_id\": tool_id,\n",
    "                        \"content\": result}\n",
    "                ]})\n",
    "                \n",
    "                response = client.messages.create(max_tokens = 2020, \n",
    "                                                  model = 'claude-3-7-sonnet-20250219',\n",
    "                                                  tools = tools,\n",
    "                                                  messages = messages)\n",
    "                \n",
    "                if len(response.content) == 1 and response.content[0].type == \"text\":\n",
    "                    print(response.content[0].text)\n",
    "                    process_query = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "430bafb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_loop():\n",
    "    print(\"Type your queries or 'quit' to exit.\")\n",
    "    while True:\n",
    "        try:\n",
    "            query = input(\"\\nQuery: \").strip()\n",
    "            if query.lower() == 'quit':\n",
    "                break\n",
    "    \n",
    "            process_query(query)\n",
    "            print(\"\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "54110ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type your queries or 'quit' to exit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query:  hi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.'}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query:  quit\n"
     ]
    }
   ],
   "source": [
    "chat_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa49e804",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
